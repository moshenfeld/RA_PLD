{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "notebook_path = pathlib.Path().absolute()\n",
    "# Add parent directory to path so we can import from PLD_accounting and Comparison\n",
    "parent_dir = notebook_path.parent\n",
    "if str(parent_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from comparisons.data_management import load_results\n",
    "from comparisons.experiments.epsilon_from_sigma import plot_epsilon_from_sigma, plot_epsilon_from_sigma_by_k, plot_epsilon_vs_k\n",
    "from comparisons.experiments.PREAMBLE import plot_PREAMBLE_experiment\n",
    "from comparisons.experiments.PREAMBLE import plot_preamble_epsilon_experiment\n",
    "from comparisons.experiments.delta_comparison import plot_delta_comparison\n",
    "from PLD_accounting.types import Direction\n",
    "from comparisons.experiments.utility_comparison import plot_utility_comparison_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2lb8i6gcjhm",
   "metadata": {},
   "source": [
    "# Fig. 1a: Epsilon from sigma (varying t, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ktcvhuakfy",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_results('epsilon_from_sigma')\n",
    "if results is None:\n",
    "    print(\"ERROR: epsilon_from_sigma results not found!\")\n",
    "else:\n",
    "    print(f\"Loaded results with keys: {list(results.keys())}\")\n",
    "    if 'params' in results:\n",
    "        print(f\"Params: {list(results['params'].keys())}\")\n",
    "    for key in results.keys():\n",
    "        if key != 'params':\n",
    "            print(f\"  {key}: {list(results[key].keys()) if isinstance(results[key], dict) else type(results[key])}\")\n",
    "    try:\n",
    "        plot_epsilon_from_sigma(results)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR plotting: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666dc06e",
   "metadata": {},
   "source": [
    "# Fig. 1c: Epsilon from sigma across k (t=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abd5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_results('epsilon_from_sigma_by_k')\n",
    "if results is None:\n",
    "    print(\"ERROR: epsilon_from_sigma_by_k results not found!\")\n",
    "else:\n",
    "    print(f\"Loaded results with keys: {list(results.keys())}\")\n",
    "    if 'params' in results:\n",
    "        print(f\"Params: {list(results['params'].keys())}\")\n",
    "    for key in results.keys():\n",
    "        if key != 'params':\n",
    "            print(f\"  {key}: {list(results[key].keys()) if isinstance(results[key], dict) else type(results[key])}\")\n",
    "    try:\n",
    "        plot_epsilon_from_sigma_by_k(results)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR plotting: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703cfc3e",
   "metadata": {},
   "source": [
    "# Fig. 1d: Epsilon vs k (σ=1, t=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd458ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_results('epsilon_vs_k')\n",
    "if results is None:\n",
    "    print(\"ERROR: epsilon_vs_k results not found!\")\n",
    "else:\n",
    "    print(f\"Loaded results with keys: {list(results.keys())}\")\n",
    "    if 'params' in results:\n",
    "        print(f\"Params: {list(results['params'].keys())}\")\n",
    "    for key in results.keys():\n",
    "        if key != 'params':\n",
    "            val = results[key]\n",
    "            if isinstance(val, dict):\n",
    "                print(f\"  {key}: {list(val.keys())}\")\n",
    "            elif isinstance(val, list):\n",
    "                print(f\"  {key}: list(len={len(val)})\")\n",
    "            else:\n",
    "                print(f\"  {key}: {type(val)}\")\n",
    "    try:\n",
    "        plot_epsilon_vs_k(results)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR plotting: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ceffa6",
   "metadata": {},
   "source": [
    "# PREAMBLE experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e51d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_results('PREAMBLE_experiment')\n",
    "plot_PREAMBLE_experiment(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k63bzzw71ci",
   "metadata": {},
   "source": [
    "# Runtime and RDP Experiment\n",
    "\n",
    "This experiment measures both the runtime and RDP accuracy of the geometric method.\n",
    "- **Runtime plot**: Shows runtime vs. 1/loss_discretization for different t values\n",
    "- **RDP plot**: Three subplots (one per t value) showing RDP vs. 1/loss_discretization with shared y-scale\n",
    "\n",
    "Both plots use the same experimental parameters, making it easy to compare runtime cost with accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yxabtdgttbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comparisons.experiments.runtime import plot_runtime_with_rdp_experiment\n",
    "\n",
    "results = load_results('runtime_experiment')\n",
    "if results is not None:\n",
    "    print(\"=\"*70)\n",
    "    print(\"Runtime and RDP Experiment Results\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Generate both runtime and RDP plots\n",
    "    runtime_fig, rdp_fig = plot_runtime_with_rdp_experiment(\n",
    "        results, \n",
    "        save_plots=False, \n",
    "        show_plots=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nGenerated two plots:\")\n",
    "    print(\"1. Runtime vs. 1/loss_discretization (single subplot)\")\n",
    "    print(\"2. RDP vs. 1/loss_discretization (three subplots with shared y-scale)\")\n",
    "else:\n",
    "    print(\"Runtime experiment results not found. Please run the experiment first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "erm81u19c3f",
   "metadata": {},
   "source": [
    "# Delta Comparison Experiment\n",
    "\n",
    "This experiment compares delta values for different methods across multiple parameter configurations.\n",
    "Similar to the Chau et al. Monte Carlo comparison experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l475xk3tmrc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_results('delta_comparison')\n",
    "if results is not None:\n",
    "    plot_delta_comparison(results, save_plots=False, show_plots=True)\n",
    "else:\n",
    "    print(\"Delta comparison results not found. Please run the experiment first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d1751",
   "metadata": {},
   "source": [
    "# Utility Comparison Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446caa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_results('utility_comparison')\n",
    "if results is None:\n",
    "    print(\"Utility comparison results not found. Please run the experiment with RUN_UTILITY_COMPARISON=True\")\n",
    "else:\n",
    "    plot_utility_comparison_results(results, show_ci=False)\n",
    "    print(f\"Plotted utility comparison for {len(results.get('experiments', []))} configurations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sknxwienndp",
   "metadata": {},
   "source": [
    "# Epsilon Loss Discretization Experiment (σ=1)\n",
    "\n",
    "This is the grid size experiment simplified to test only σ=1.  \n",
    "Compares geometric vs FFT convolution methods across varying grid sizes.  \n",
    "Shows epsilon-delta accuracy with runtime and memory profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6gw80pom56u",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting function\n",
    "from comparisons.experiments.grid_size import plot_grid_size_combined_all_directions\n",
    "\n",
    "# Load epsilon loss_discretization results (sigma=1 only)\n",
    "epsilon_disc_results = load_results('epsilon_discretization')\n",
    "\n",
    "if epsilon_disc_results is not None:\n",
    "    print(\"=\"*70)\n",
    "    print(\"Epsilon Loss Discretization Experiment Results (σ=1)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nAvailable result keys: {list(epsilon_disc_results.keys())}\")\n",
    "\n",
    "    # Plot epsilon results (delta=1e-6, sigma=1.0)\n",
    "    print(f\"\\nPlotting ε for δ = 1e-06, σ = 1.0\")\n",
    "    fig, axs = plot_grid_size_combined_all_directions(\n",
    "        epsilon_disc_results,\n",
    "        delta=1e-6\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Epsilon loss_discretization results not found.\")\n",
    "    print(\"Please run the experiment with RUN_EPSILON_DISCRETIZATION=True in paper_experiments.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fqrpr8d2gwc",
   "metadata": {},
   "source": [
    "# Subsampling Bounds Comparison\n",
    "\n",
    "Compare subsampling via four competitors:\n",
    "1. Analytic (Gaussian mixture ground truth)\n",
    "2. dp_accounting (Gaussian mechanism with subsampling)\n",
    "3. Our upper bound (subsample_PMF bounds)\n",
    "4. Our lower bound (subsample_PMF bounds)\n",
    "\n",
    "The plots show the CDF comparison and epsilon-ratio comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4p26mi2nnga",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comparisons.experiments.subsampling_comparison import plot_subsampling_comparison\n",
    "\n",
    "subsampling_results = load_results(\"subsampling_comparison\")\n",
    "if subsampling_results is None:\n",
    "    print(\"Subsampling comparison results not found. Please run run_subsampling_comparison first.\")\n",
    "else:\n",
    "    print(\"=\"*70)\n",
    "    print(\"Subsampling Bounds Comparison\")\n",
    "    print(\"=\"*70)\n",
    "    params = subsampling_results['params']\n",
    "    print(f\"Parameters: σ={params['sigma']}, q={params['sampling_prob']}, discretization={params['discretization']}\")\n",
    "    plot_subsampling_comparison(subsampling_results, direction=\"remove\", show_plots=True, save_plots=False)\n",
    "    plot_subsampling_comparison(subsampling_results, direction=\"add\", show_plots=True, save_plots=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5198a7b5",
   "metadata": {},
   "source": [
    "# PREAMBLE epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a77ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_results('preamble_epsilon_experiment')\n",
    "plot_preamble_epsilon_experiment(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
